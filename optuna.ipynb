{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from corpusholder import Lang, CorpusHolder\n",
    "from model import Model, Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim_model loaded\n"
     ]
    }
   ],
   "source": [
    "gensim_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "print('gensim_model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data=(249354, 11)\n",
      "Lang=30002\n",
      "CorpusHolder train_dataset=199472 val_dataset=24934 test_dataset=24935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexey/.conda/envs/py37/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Liked', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AMAZON FOODS import\n",
    "data = pd.read_csv('./amazon_foods/Reviews.csv')\n",
    "data['Liked'] = data['Score'].apply(lambda x : 1 if x >= 4 else 0)\n",
    "\n",
    "negatives = data[data.Liked == 0]\n",
    "positives = data[data.Liked == 1].sample(n=len(negatives), random_state=1000007)\n",
    "data = shuffle(positives.append(negatives).reset_index(drop=True))\n",
    "print('data=%s' % str(data.shape))\n",
    "corpus_holder = CorpusHolder(data['Text'].values, data['Liked'].values)\n",
    "sns.countplot(data['Liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153105</th>\n",
       "      <td>125873</td>\n",
       "      <td>B005MGDP90</td>\n",
       "      <td>A26SYXM0IZMYPN</td>\n",
       "      <td>David</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1347062400</td>\n",
       "      <td>missing salt</td>\n",
       "      <td>i went a picked up my order today and the box ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>395290</td>\n",
       "      <td>B000H7ELTW</td>\n",
       "      <td>AYDS27E60FH0A</td>\n",
       "      <td>Glenn Leary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1247184000</td>\n",
       "      <td>Superb Cranberries</td>\n",
       "      <td>&lt;a href=\"http://www.amazon.com/gp/product/B000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210422</th>\n",
       "      <td>387654</td>\n",
       "      <td>B000633Y4A</td>\n",
       "      <td>AC7AY7GU4GKID</td>\n",
       "      <td>Mom of the Year</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1340755200</td>\n",
       "      <td>Contains chicken!</td>\n",
       "      <td>Why does this bone have to contain chicken mea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91394</th>\n",
       "      <td>456393</td>\n",
       "      <td>B005F0JM7W</td>\n",
       "      <td>A2EX2DK4BO680S</td>\n",
       "      <td>N. Williams</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1337990400</td>\n",
       "      <td>Great storage for k cups</td>\n",
       "      <td>This was easy to install. After reading other ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58244</th>\n",
       "      <td>442757</td>\n",
       "      <td>B001ELL2HO</td>\n",
       "      <td>AXJD9GZIJP2BH</td>\n",
       "      <td>Savvy Shopper</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1299024000</td>\n",
       "      <td>Perfect for Snacking!</td>\n",
       "      <td>This is my second order of this wonderful ging...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId      ProfileName  \\\n",
       "153105  125873  B005MGDP90  A26SYXM0IZMYPN            David   \n",
       "25478   395290  B000H7ELTW   AYDS27E60FH0A      Glenn Leary   \n",
       "210422  387654  B000633Y4A   AC7AY7GU4GKID  Mom of the Year   \n",
       "91394   456393  B005F0JM7W  A2EX2DK4BO680S      N. Williams   \n",
       "58244   442757  B001ELL2HO   AXJD9GZIJP2BH    Savvy Shopper   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "153105                     1                       8      2  1347062400   \n",
       "25478                      0                       0      5  1247184000   \n",
       "210422                     9                       9      2  1340755200   \n",
       "91394                      2                       2      5  1337990400   \n",
       "58244                      3                       3      5  1299024000   \n",
       "\n",
       "                         Summary  \\\n",
       "153105              missing salt   \n",
       "25478         Superb Cranberries   \n",
       "210422         Contains chicken!   \n",
       "91394   Great storage for k cups   \n",
       "58244      Perfect for Snacking!   \n",
       "\n",
       "                                                     Text  Liked  \n",
       "153105  i went a picked up my order today and the box ...      0  \n",
       "25478   <a href=\"http://www.amazon.com/gp/product/B000...      1  \n",
       "210422  Why does this bone have to contain chicken mea...      0  \n",
       "91394   This was easy to install. After reading other ...      1  \n",
       "58244   This is my second order of this wonderful ging...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparamers search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try Optuna\n",
    "<br>\n",
    "https://optuna.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-05 21:32:10,253]\u001b[0m A new study created in memory with name: no-name-1e2a70ac-ca75-41e6-97f9-8fe3942908cd\u001b[0m\n",
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc=0.8134 test_acc=0.8174 saving optuna.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-05 21:59:41,816]\u001b[0m Trial 0 finished with value: 0.8134274484639448 and parameters: {'hidden_size': 282, 'num_layers': 3, 'cell_dropout': 2.718868794297591e-07, 'bidirectional': False, 'hidden_layer_size': 321, 'lr': 1.640907641328538e-05, 'weight_decay': 0.00036535885202272097}. Best is trial 0 with value: 0.8134274484639448.\u001b[0m\n",
      "\u001b[32m[I 2020-12-05 22:34:15,069]\u001b[0m Trial 1 finished with value: 0.7496189941445416 and parameters: {'hidden_size': 363, 'num_layers': 3, 'cell_dropout': 2.3319413973687234e-05, 'bidirectional': False, 'hidden_layer_size': 235, 'lr': 1.0644711433703698e-05, 'weight_decay': 0.01415630739347542}. Best is trial 0 with value: 0.8134274484639448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc=0.8359 test_acc=0.8349 saving optuna.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-05 23:15:31,062]\u001b[0m Trial 2 finished with value: 0.8358867409962301 and parameters: {'hidden_size': 448, 'num_layers': 3, 'cell_dropout': 0.43919840866757914, 'bidirectional': False, 'hidden_layer_size': 165, 'lr': 1.786899533000722e-05, 'weight_decay': 6.969531163516794e-07}. Best is trial 2 with value: 0.8358867409962301.\u001b[0m\n",
      "\u001b[32m[I 2020-12-05 23:23:38,075]\u001b[0m Trial 3 finished with value: 0.817157295259485 and parameters: {'hidden_size': 106, 'num_layers': 2, 'cell_dropout': 0.033661418785245735, 'bidirectional': False, 'hidden_layer_size': 53, 'lr': 2.0341859784597604e-05, 'weight_decay': 9.426030036563326e-08}. Best is trial 2 with value: 0.8358867409962301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc=0.8393 test_acc=0.8441 saving optuna.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-05 23:53:16,983]\u001b[0m Trial 4 finished with value: 0.8392556348760728 and parameters: {'hidden_size': 87, 'num_layers': 3, 'cell_dropout': 1.33416602672771e-05, 'bidirectional': True, 'hidden_layer_size': 235, 'lr': 6.578286448504483e-05, 'weight_decay': 5.878047428529228e-05}. Best is trial 4 with value: 0.8392556348760728.\u001b[0m\n",
      "/home/alexey/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1.3064924561012057e-07 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[32m[I 2020-12-05 23:58:09,418]\u001b[0m Trial 5 finished with value: 0.8090158017165316 and parameters: {'hidden_size': 135, 'num_layers': 1, 'cell_dropout': 1.3064924561012057e-07, 'bidirectional': False, 'hidden_layer_size': 91, 'lr': 1.631715686663154e-05, 'weight_decay': 1.418738066338229e-06}. Best is trial 4 with value: 0.8392556348760728.\u001b[0m\n",
      "\u001b[32m[I 2020-12-06 00:11:10,438]\u001b[0m Trial 6 finished with value: 0.8153525306809979 and parameters: {'hidden_size': 11, 'num_layers': 2, 'cell_dropout': 1.8532187276690985e-08, 'bidirectional': True, 'hidden_layer_size': 155, 'lr': 5.8299678171828636e-05, 'weight_decay': 4.320061006121221e-06}. Best is trial 4 with value: 0.8392556348760728.\u001b[0m\n",
      "\u001b[32m[I 2020-12-06 00:42:19,255]\u001b[0m Trial 7 finished with value: 0.8399775407074677 and parameters: {'hidden_size': 101, 'num_layers': 3, 'cell_dropout': 2.3064706714539536e-06, 'bidirectional': True, 'hidden_layer_size': 334, 'lr': 4.618195828217964e-05, 'weight_decay': 3.16361941279662e-07}. Best is trial 7 with value: 0.8399775407074677.\u001b[0m\n",
      "/home/alexey/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1.65554262482122e-05 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[32m[I 2020-12-06 00:48:39,813]\u001b[0m Trial 8 finished with value: 0.8072110371380444 and parameters: {'hidden_size': 19, 'num_layers': 1, 'cell_dropout': 1.65554262482122e-05, 'bidirectional': True, 'hidden_layer_size': 331, 'lr': 0.00016236731155159432, 'weight_decay': 0.007431093844326988}. Best is trial 7 with value: 0.8399775407074677.\u001b[0m\n",
      "\u001b[32m[I 2020-12-06 01:27:07,090]\u001b[0m Trial 9 finished with value: 0.8413812464907355 and parameters: {'hidden_size': 402, 'num_layers': 3, 'cell_dropout': 6.206463214478765e-05, 'bidirectional': False, 'hidden_layer_size': 29, 'lr': 3.0029930972852028e-05, 'weight_decay': 2.7526992241650055e-06}. Best is trial 9 with value: 0.8413812464907355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc=0.8906 test_acc=0.8950 saving optuna.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-06 01:55:22,538]\u001b[0m Trial 10 finished with value: 0.8905510547846315 and parameters: {'hidden_size': 482, 'num_layers': 2, 'cell_dropout': 0.003295677635229789, 'bidirectional': False, 'hidden_layer_size': 521, 'lr': 0.0009041436310896368, 'weight_decay': 1.5047840888981153e-09}. Best is trial 10 with value: 0.8905510547846315.\u001b[0m\n",
      "\u001b[32m[I 2020-12-06 02:25:20,154]\u001b[0m Trial 11 finished with value: 0.8881045961337932 and parameters: {'hidden_size': 510, 'num_layers': 2, 'cell_dropout': 0.0027716675301965804, 'bidirectional': False, 'hidden_layer_size': 511, 'lr': 0.0006322070161468966, 'weight_decay': 1.3001775393426583e-09}. Best is trial 10 with value: 0.8905510547846315.\u001b[0m\n",
      "\u001b[32m[I 2020-12-06 02:56:35,509]\u001b[0m Trial 12 finished with value: 0.8907916900617631 and parameters: {'hidden_size': 517, 'num_layers': 2, 'cell_dropout': 0.00420862245769795, 'bidirectional': False, 'hidden_layer_size': 521, 'lr': 0.0009863582920848623, 'weight_decay': 1.5037412617546807e-09}. Best is trial 12 with value: 0.8907916900617631.\u001b[0m\n",
      "\u001b[32m[I 2020-12-06 03:27:40,359]\u001b[0m Trial 13 finished with value: 0.8922355017245528 and parameters: {'hidden_size': 513, 'num_layers': 2, 'cell_dropout': 0.0017920113314309712, 'bidirectional': False, 'hidden_layer_size': 515, 'lr': 0.0008372984740100813, 'weight_decay': 1.0063959312176523e-09}. Best is trial 13 with value: 0.8922355017245528.\u001b[0m\n",
      "/home/alexey/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0008304772355456052 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[32m[I 2020-12-06 03:35:35,023]\u001b[0m Trial 14 finished with value: 0.8793214085184888 and parameters: {'hidden_size': 302, 'num_layers': 1, 'cell_dropout': 0.0008304772355456052, 'bidirectional': False, 'hidden_layer_size': 447, 'lr': 0.000331924034783001, 'weight_decay': 1.891332372586496e-08}. Best is trial 13 with value: 0.8922355017245528.\u001b[0m\n",
      "\u001b[32m[I 2020-12-06 04:06:40,647]\u001b[0m Trial 15 finished with value: 0.8900296783508462 and parameters: {'hidden_size': 515, 'num_layers': 2, 'cell_dropout': 0.2773142221388686, 'bidirectional': False, 'hidden_layer_size': 431, 'lr': 0.0004427627511587934, 'weight_decay': 9.46404712908375e-09}. Best is trial 13 with value: 0.8922355017245528.\u001b[0m\n",
      "\u001b[32m[I 2020-12-06 04:17:56,105]\u001b[0m Trial 16 finished with value: 0.8725034089997593 and parameters: {'hidden_size': 187, 'num_layers': 2, 'cell_dropout': 0.035629402470456664, 'bidirectional': False, 'hidden_layer_size': 427, 'lr': 0.00019677324325714622, 'weight_decay': 1.0944171002607024e-09}. Best is trial 13 with value: 0.8922355017245528.\u001b[0m\n",
      "/home/alexey/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.00042236809604105467 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[32m[I 2020-12-06 04:28:24,261]\u001b[0m Trial 17 finished with value: 0.890831795941285 and parameters: {'hidden_size': 377, 'num_layers': 1, 'cell_dropout': 0.00042236809604105467, 'bidirectional': False, 'hidden_layer_size': 526, 'lr': 0.0009222031376453259, 'weight_decay': 1.2103394943063237e-08}. Best is trial 13 with value: 0.8922355017245528.\u001b[0m\n",
      "/home/alexey/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.00013535657131618614 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[32m[I 2020-12-06 04:37:19,839]\u001b[0m Trial 18 finished with value: 0.8862196197962622 and parameters: {'hidden_size': 356, 'num_layers': 1, 'cell_dropout': 0.00013535657131618614, 'bidirectional': False, 'hidden_layer_size': 469, 'lr': 0.0002979508773656842, 'weight_decay': 3.1088556830971434e-08}. Best is trial 13 with value: 0.8922355017245528.\u001b[0m\n",
      "/home/alexey/.conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0003645777425887407 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[32m[I 2020-12-06 04:49:28,502]\u001b[0m Trial 19 finished with value: 0.8850966551696479 and parameters: {'hidden_size': 430, 'num_layers': 1, 'cell_dropout': 0.0003645777425887407, 'bidirectional': False, 'hidden_layer_size': 380, 'lr': 0.0006260349698276447, 'weight_decay': 8.415552242667781e-09}. Best is trial 13 with value: 0.8922355017245528.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from optuna import create_study\n",
    "\n",
    "BEST_ACC = 0.6\n",
    "\n",
    "def objective(trial):\n",
    "    global BEST_ACC\n",
    "\n",
    "    model_config = {'embedding_freeze': True, \n",
    "                    'gru_hidden_size': trial.suggest_int(\"hidden_size\", 10, 526), \n",
    "                    'gru_num_layers': trial.suggest_int(\"num_layers\", 1, 3),\n",
    "                    'gru_dropout':trial.suggest_loguniform(\"cell_dropout\", 1e-9, 0.9), \n",
    "                    'gru_bidirectional': trial.suggest_categorical(\"bidirectional\", [True, False]), \n",
    "                    'fc_size': trial.suggest_int(\"hidden_layer_size\", 10, 526), \n",
    "                    'n_classes': 2}\n",
    "\n",
    "    trymodel = Model(corpus_holder.lang, gensim_model, model_config)\n",
    "    \n",
    "    learner_config = {'learning_rate': trial.suggest_loguniform(\"lr\", 1e-5, 1e-3), \n",
    "                      'n_epoch': 12, \n",
    "                      'weight_decay':trial.suggest_loguniform(\"weight_decay\", 1e-9, 1e-1), \n",
    "                      'verbose': False}\n",
    "    \n",
    "    learner = Learner(trymodel, learner_config)\n",
    "    val_acc, test_acc = learner.train(corpus_holder)\n",
    "\n",
    "    if test_acc > BEST_ACC:\n",
    "        BEST_ACC = test_acc\n",
    "        print('val_acc=%.4f test_acc=%.4f saving optuna.ckpt' % (val_acc, test_acc))\n",
    "        learner.save(\"optuna.ckpt\")\n",
    "    return val_acc\n",
    "\n",
    "study = create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
